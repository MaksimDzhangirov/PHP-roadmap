# Дорожная карта для изучения Docker

[Оригинал](https://roadmap.sh/docker)

Дорожная карта была составлена в сотрудничестве с [Сидом Паласом (Sid Palas)](https://twitter.com/sidpalas). Ознакомьтесь с его
[бесплатным курсом, подробно освещающим эту тему](https://courses.devopsdirective.com/docker-beginner-to-pro).

[Дорожная карта для изучения Kubernetes](https://roadmap.sh/kubernetes)

[Дорожная карта DevOps](https://roadmap.sh/devops)

[Дорожная карта Backend-разработчика](https://roadmap.sh/backend)

Необходимые предварительные знания для изучения данного материала:

* из области веб-разработки
  * архитектура приложения
  * языки программирования
* основ Linux
  * менеджеры пакетов
  * права доступа для пользователей/групп
  * команды оболочки командной строки
  * скрипты оболочки командной строки
 
## Введение

**Что такое Docker?**

Docker – это платформа с открытым исходным кодом, которая автоматизирует развертывание, масштабирование и управление приложениями, изолируя их в легковесные портативные контейнеры. Контейнеры – это автономные исполняемые модули, которые инкапсулируют все необходимые зависимости, библиотеки и файлы конфигурации, необходимые для единообразной работы приложения в различных средах.

### Что такое контейнеры?

Контейнеры – это легковесные, портативные и изолированные программные среды, которые позволяют разработчикам запускать и упаковывать приложения с их зависимостями единообразно на разных платформах. Они помогают оптимизировать процессы разработки, развертывания и управления приложениями, обеспечивая при этом единообразную работу приложений независимо от базовой инфраструктуры.

#### Как работают контейнеры?

В отличие от традиционной виртуализации, которая эмулирует всю операционную систему с ее аппаратными ресурсами, контейнеры совместно используют ядро ОС хоста и упрощенные методы виртуализации для создания изолированных процессов. Такой подход дает ряд преимуществ, в том числе:

* **Эффективность**: контейнеры требуют меньше накладных расходов и могут совместно использовать общие библиотеки и исполняемые файлы, что позволяет запускать больше контейнеров на одном хосте по сравнению с виртуальными машинами (ВМ).
* **Переносимость**: контейнеры инкапсулируют приложения и их зависимости, поэтому их можно легко перемещать и единообразно запускать в разных средах и платформах.
* **Быстрый запуск**: поскольку контейнерам не требуется загрузка полной ОС, они могут запускаться и завершать работу гораздо быстрее, чем виртуальные машины.
* **Единообразность**: контейнеры обеспечивают единообразную среду для этапов разработки, тестирования и продакшена приложения, уменьшая проблему «оно работает на моей машине».

#### Контейнеры и Docker

Docker – это платформа, которая упрощает процесс создания, развертывания и управления контейнерами. Она предоставляет разработчикам и администраторам набор инструментов и API для управления контейнерными приложениями. С помощью Docker вы можете создавать и упаковывать код приложения, библиотеки и зависимости в образ контейнера, который можно распространять и единообразно запускать в любой среде, поддерживающей Docker.

Полезные ссылки:

* [What is a container?](https://www.docker.com/resources/what-container/)

### Зачем нам нужны контейнеры?

В мире разработки и развертывания программного обеспечения решающее значение имеют единообразность и эффективность. До того, как появились контейнеры, разработчики часто сталкивались с проблемами при развертывании приложений в различных средах, в том числе:

* **Несовместимые среды**: разработчики часто работают в разных средах, которые могут иметь разные конфигурации и библиотеки по сравнению с продакшен серверами. Это приводит к проблемам совместимости при развертывании приложений.

* **Неэффективное использование ресурсов**: виртуальные машины (ВМ) широко использовались для устранения несовместимости среды. Однако виртуальные машины требуют, чтобы для каждого приложения работала целая ОС, что приводит к неэффективному использованию ресурсов.

* **Проблемы, связанные с медленным процессом внедрения и масштабируемостью**: традиционным методам развертывания требуется больше времени до выпуска решения на рынок и их трудно масштабировать, что затрудняет быстрое внедрение обновлений программного обеспечения.

Как контейнеры решают эти проблемы:

* **Единообразная среда**: контейнеры устраняют несогласованность среды, объединяя приложение и его зависимости, конфигурации и библиотеки в один контейнер. Это гарантирует бесперебойную работу приложения в различных средах.

* **Эффективное использование ресурсов**. В отличие от виртуальных машин, контейнеры совместно используют базовые системные ресурсы и ядро ОС, что делает их легковесными и эффективными. Контейнеры создавались таким образом, чтобы использовать меньшее количество ресурсов и для более быстрой загрузки, что улучшает использование ресурсов.

* **Ускорение процесса внедрения и масштабируемость**. Контейнеры можно легко создавать, уничтожать и заменять, что приводит к ускорению циклов разработки и развертывания. Масштабирование приложений упрощается, поскольку можно развернуть несколько контейнеров без потребления значительных ресурсов.

В целом контейнеры стали важным инструментом для организаций, которые хотят быстро реагировать на изменения рынка, повышать эффективность использования ресурсов и обеспечивать надежную и единообразную доставку программного обеспечения. Они произвели революцию в современной практике разработки программного обеспечения и оказали долгосрочное влияние на мир развертывания и управления приложениями.

Полезные ссылки:

* [Introduction to containers - AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/106/introduction-to-containers)

### Bare Metal, виртуальные машины и контейнеры

Вот краткий обзор различий между bare metal, виртуальными машинами и контейнерами.

#### Bare Metal

Bare Metal («голое железо») – это термин, используемый для описания компьютера, который работает непосредственно на оборудовании без какой-либо виртуализации. Это наиболее производительный способ запуска приложения, но он также и наименее гибкий. Вы можете запускать только одно приложение на каждом сервере и вы не можете легко переместить приложение на другой сервер.

#### Виртуальные машины

Виртуальные машины (ВМ) – это способ запуска нескольких приложений на одном сервере. Каждая виртуальная машина работает поверх гипервизора – программного обеспечения, эмулирующего аппаратное обеспечение компьютера. Гипервизор позволяет запускать несколько операционных систем на одном сервере, а также обеспечивает изоляцию между приложениями, работающими на разных виртуальных машинах.

#### Контейнеры

Контейнеры – это способ запуска нескольких приложений на одном сервере без затрат на гипервизор. Каждый контейнер работает поверх механизма контейнера, который представляет собой часть программного обеспечения, эмулирующую операционную систему компьютера. Механизм контейнеров позволяет запускать несколько приложений на одном сервере, а также обеспечивает изоляцию между приложениями, работающими в разных контейнерах.

Полезные ссылки:

* [History of Virtualization](https://courses.devopsdirective.com/docker-beginner-to-pro/lessons/01-history-and-motivation/03-history-of-virtualization)

### Docker и OCI

[Open Container Initiative (OCI)](https://opencontainers.org/) – это проект Linux Foundation, целью которого является создание отраслевых стандартов для форматов контейнеров и сред выполнения. Его основная цель – обеспечить совместимость и взаимодействие контейнерных сред посредством определенных технических спецификаций.

#### Роль Docker в OCI

[Docker](https://www.docker.com/) является одним из основателей OCI и сыграл ключевую роль в формировании стандартов форматов контейнеров и сред выполнения. Docker изначально разработал среду выполнения контейнера (Docker Engine) и формат образа (Docker Image), которые служат основой для спецификаций OCI.

#### Спецификации OCI

OCI имеет две основные спецификации:

* **Спецификация среды выполнения (runtime-spec)**: определяет спецификацию среды выполнения контейнера с помощью технологии изоляции, например, механизма контейнера. Среда выполнения контейнера, созданная Docker и называемая «containerd», послужила основой для разработки OCI runtime-spec.
* **Спецификация образа (image-spec)**: определяет формат образа контейнера, который описывает содержимое контейнера и может запускаться совместимой средой выполнения. Первоначальный формат образа Docker привел к созданию OCI image-spec.

#### Совместимость между Docker и OCI

Docker сохраняет приверженность к поддержке спецификаций OCI и с момента своего участия в OCI постоянно обновляет свое программное обеспечение, чтобы оно соответствовало стандартам OCI. Среда выполнения контейнера и формат образа Docker полностью совместимы со спецификациями OCI, что позволяет запускать контейнеры Docker другими средами выполнения контейнеров, совместимыми с OCI, и наоборот.

Таким образом, Docker и Open Container Initiative работают сообща, чтобы поддерживать стандартизацию и совместимость в контейнерной индустрии. Docker сыграл значительную роль в разработке спецификаций OCI, гарантируя, что экосистема контейнеров останется работоспособной, функциональной и доступной для широкого круга пользователей и платформ в отрасли.

## Технологии, лежащие в основе

Достаточно иметь общее представление о них.

Понимание основных технологий, лежащих в основе Docker, даст вам более глубокое осмысление того, как работает Docker, и поможет вам более эффективно использовать платформу.

#### Контейнеры Linux (LXC)

Контейнеры Linux (LXC) служат основой Docker. LXC – это легковесное решение для виртуализации, которое позволяет нескольким изолированным системам Linux работать на одном хосте без необходимости использования полноценного гипервизора. LXC эффективно изолирует приложения и их зависимости безопасным и оптимизированным способом.

#### Контрольные группы (cgroups)

Контрольные группы (cgroups) – это функция ядра Linux, которая позволяет распределять и управлять такими ресурсами, как ЦП, память и ввод-вывод, набору процессов. Docker использует контрольные группы, чтобы ограничить ресурсы, используемые контейнерами, и гарантировать, что один контейнер не монополизирует ресурсы хост-системы.

#### Файловые системы типа Union

UnionFS – это служба файловой системы, которая позволяет накладывать несколько файловых систем, формируя единое унифицированное представление. Docker использует UnionFS для создания многоуровневого подхода к образам и контейнерам, что обеспечивает лучший обмен общими файлами и более быстрое создание контейнеров.

#### Пространства имён

Пространства имён – ещё одна функция ядра Linux, обеспечивающая изоляцию процессов. Они позволяют Docker создавать изолированные рабочие области, называемые контейнерами. Пространства имен гарантируют, что процессы внутри контейнера не могут мешать процессам вне контейнера или в хост-системе. Существует несколько типов пространств имен, таких как PID, NET, MNT и USER, каждый из которых отвечает за изоляцию определенного аспекта процесса.

### Пространство имён

Пространства имён – одна из основных технологий, которые Docker использует для обеспечения изоляции между контейнерами. В этом разделе мы кратко обсудим, что такое пространства имён и как они работают.

#### Что такое пространства имён?

В ядре Linux пространства имен – это функционал, который позволяет изолировать различные системные ресурсы, позволяя процессу и его дочерним элементам работать в обособленном подмножестве системы, отдельном от других процессов. Пространства имён помогают создать уровень абстракции, позволяющий хранить контейнерные процессы отдельно друг от друга и от хост-системы.

В Linux существует несколько типов пространств имен, а именно:

* **PID (идентификаторы процессов)**: изолирует пространство номеров идентификаторов процессов. Это означает, что процессы внутри контейнера видят только свои собственные процессы, а не процессы на хосте или в других контейнерах.
* **Сеть (NET)**: предоставляет каждому контейнеру отдельное представление сетевого стека, включая собственные сетевые интерфейсы, таблицы маршрутизации и правила брандмауэра.
* **Монтирование (MNT)**: изолирует точки монтирования файловой системы таким образом, что каждый контейнер имеет собственную корневую файловую систему, а смонтированные ресурсы видны только внутри этого контейнера.
* **UTS (система разделения времени UNIX)**: позволяет каждому контейнеру иметь собственное имя хоста и имя домена, отдельно от других контейнеров и хост-системы.
* **Пользователь (USER)**: сопоставляет идентификаторы пользователя и группы между контейнером и хостом, поэтому для ресурсов внутри контейнера можно устанавливать разные права доступа.
* **IPC (межпроцессное взаимодействие)**: разрешает или ограничивает взаимодействие между процессами в разных контейнерах.

#### Как Docker использует пространства имен

Docker использует пространства имен, создавая изолированные среды для контейнеров. Когда контейнер запускается, Docker создает для этого контейнера новый набор пространств имен. Эти пространства имен действуют только внутри контейнера, поэтому любые процессы, работающие внутри контейнера, имеют доступ к подмножеству системных ресурсов, изолированных от других контейнеров, а также от хост-системы.

Используя пространства имен, Docker гарантирует, что контейнеры действительно переносимы и могут работать в любой системе без конфликтов или вмешательства со стороны других процессов или контейнеров, работающих на том же хосте.

Подводя итог, можно сказать, что пространства имен обеспечивают уровень изоляции ресурсов, который позволяет запускать несколько контейнеров с отдельными системными ресурсами на одном хосте, не мешая им друг другу. Это важнейшая функция, которая составляет основу контейнерной технологии Docker.

### cgroups

**cgroups** или **контрольные группы** – это функционал ядра Linux, которая позволяет вам распределять и управлять ресурсами, такими как ЦП, память, пропускная способность сети и ввод-вывод, между группами процессов, запущенных в системе. Он играет решающую роль в обеспечении изоляции ресурсов и ограничении ресурсов, которые может использовать работающий контейнер.

Docker использует cgroups для обеспечения соблюдения ограничений ресурсов в контейнерах, позволяя им иметь единообразное и предсказуемое поведение. Ниже приведены некоторые ключевые функции и преимущества cgroups в контексте контейнеров Docker:

#### Изоляция ресурсов

cgroups помогает ограничить каждый контейнер определенным набором ресурсов, гарантируя справедливое разделение системных ресурсов между несколькими контейнерами. Это обеспечивает лучшую изоляцию между различными контейнерами, так что сбоящий контейнер не потребляет все доступные ресурсы, тем самым негативно влияя на другие контейнеры.

#### Ограничение ресурсов

С помощью cgroups вы можете установить ограничения на различные системные ресурсы, используемые контейнером, такие как процессор, память и ввод-вывод. Это помогает предотвратить потребление чрезмерных ресурсов одним контейнером и возникновение проблем с производительностью других контейнеров или хост-системы.

#### Приоритизация контейнеров

Выделяя различные доли ресурсов, cgroups позволяет вам отдавать предпочтение или приоритет определенным контейнерам. Это может быть полезно в случаях, где некоторые контейнеры более критичны, чем другие, или в ситуациях с высокой конкуренцией за ресурсы.

#### Мониторинг

cgroups также предлагает механизмы мониторинга использования ресурсов отдельными контейнерами, что помогает получить представление о производительности контейнеров и выявить потенциальные узкие места в ресурсах.

В целом, cgroups – это важная базовая технология Docker. Используя cgroups, Docker обеспечивает надежную и эффективную среду выполнения контейнеров, гарантируя, что контейнеры имеют необходимые ресурсы, сохраняя при этом хорошую общую производительность системы.

### Файловые системы типа Union

Файловые системы типа Union, также известные как UnionFS, играют решающую роль в общем функционировании Docker. Это уникальный тип файловой системы, который создает виртуальную многоуровневую файловую структуру путем наложения нескольких каталогов. Вместо изменения исходной файловой системы или объединения каталогов UnionFS позволяет одновременно монтировать несколько каталогов в одной точке монтирования, сохраняя при этом их содержимое отдельно. Эта функция особенно полезна в контексте Docker, поскольку позволяет нам контролировать и оптимизировать производительность хранилища за счет минимизации дублирования и уменьшения размера образа контейнера.

Вот некоторые из основных особенностей файловых систем типа Union:

* **Многоуровневая структура**: UnionFS создает многоуровневую структуру, состоящую из нескольких слоев, доступных только для чтения, и верхнего слоя, доступного для записи. Эта структура позволяет эффективно обрабатывать изменения, обновляя только записываемый слой, в то время как слои, доступные только для чтения, сохраняют исходные данные.

* **Копирование при записи**: Механизм копирования при записи (COW) является незаменимой функцией UnionFS. Если контейнер вносит изменения в существующий файл, система создает копию файла в доступном для записи слое, оставляя исходный файл в слое только для чтения нетронутым. Этот процесс ограничивает модификацию самым верхним слоем, обеспечивая быструю и ресурсоэффективную работу.

* **Совместное использование ресурсов**: файловые системы типа Union позволяют нескольким контейнерам использовать общие базовые слои при раздельной работе. Эта функция предотвращает дублирование ресурсов и экономит значительное место под хранение.

* **Быстрая инициализация контейнера**: Файловые системы типа Union позволяют мгновенно создавать новые контейнеры, просто создавая новый записываемый слой на существующих слоях, доступных только для чтения. Такая быстрая инициализация снижает накладные расходы на дублированные файловые операции, что в конечном итоге повышает производительность.

#### Популярные файловые системы типа Union в Docker

Docker поддерживает несколько файловых систем типа Union, которые упрощают создание контейнеров и управление ими. Некоторыми из популярных вариантов явлются:

* **AUFS (расширенная многоуровневая унифицированная файловая система)**: AUFS широко используется в качестве драйвера хранилища Docker, обеспечивая эффективное управление несколькими слоями.
* **OverlayFS (файловая система Overlay)**: OverlayFS – ещё одна файловая система типа Union, поддерживаемая Docker. Он использует упрощенный подход по сравнению с AUFS для создания и управления наложенными друг на друга каталогами.
* **Btrfs (файловая система B-Tree)**: Btrfs, современная файловая система, обеспечивает совместимость с файловыми системами типа Union в дополнение к расширенным функциям хранения, таким как снимки состояния файлов и контрольные суммы.
* **ZFS (файловая система Z)**: ZFS – это высокопроизводительная и надежная платформа хранения, которая обеспечивает функции файловой системы типа Union, а также защиту данных, сжатие и дедупликацию.

## Установка/Настройка

Docker предоставляет настольное приложение под названием **Docker Desktop**, которое упрощает процесс установки и настройки. Существует также другой вариант установки с помощью **Docker Engine**.

Полезные ссылки:

* [Docker Desktop website](https://www.docker.com/products/docker-desktop)
* [Docker Engine](https://docs.docker.com/engine/install/)

### Docker Desktop (Win/Mac/Linux)

Docker Desktop – это простое в установке приложение, которое позволяет разработчикам быстро настроить среду Docker на своих настольных компьютерах. Оно доступно как для операционных систем Windows, так и для MacOS. Docker Desktop предназначен для упрощения процесса управления и запуска контейнеров Docker, обеспечивая удобный интерфейс и бесшовную интеграцию с операционной системой хоста.

**Характерные особенности**

* **Простота установки**: Docker Desktop обеспечивает простой процесс установки, позволяя пользователям быстро настроить Docker на своих компьютерах.
* **Автоматические обновления**: Приложение автоматически обновится до последней версии Docker, гарантируя актуальность и безопасность вашей среды.
* **Интеграция с Docker Hub**: Интерфейс Docker Desktop обеспечивает легкий доступ к Docker Hub, позволяя пользователям находить, делиться и управлять Docker образами.
* **Управление контейнерами и сервисами**: Docker Desktop упрощает управление контейнерами и сервисами благодаря удобному графическому интерфейсу, который позволяет пользователям следить за состоянием, запускать, останавливать и удалять контейнеры и сервисы.
* **Интеграция с Kubernetes**: Docker Desktop поставляется со встроенной поддержкой Kubernetes, которую можно включить одним щелчком мыши. Это упрощает разработку, тестирование и запуск Kubernetes приложений локально.
* **Распределение ресурсов**: Docker Desktop позволяет пользователям настраивать объем ресурсов (ЦП, оперативной памяти и твердотельного или дискового накопителя), выделяемых контейнерам и службам.

**Установка**

Чтобы установить Docker Desktop на свой компьютер, выполните следующие действия:

* **Загрузите установщик**. Вы можете загрузить установщик для своей операционной системы с [веб-сайта Docker Desktop](https://www.docker.com/products/docker-desktop). Обязательно выберите подходящую версию (Windows или Mac).
* **Запустите установщик**: дважды щелкните по загруженному файлу установщика и следуйте указаниям мастера установки, чтобы завершить процесс установки.
* **Запустите Docker Desktop**: После завершения установки запустите Docker Desktop и войдите в свою учетную запись Docker Hub. Если у вас нет учетной записи, вы можете зарегистрировать бесплатную учетную запись на [веб-сайте Docker Hub](https://hub.docker.com/).
* **Проверьте корректность установки**: откройте терминал или командную строку и выполните следующую команду, чтобы убедиться, что Docker Desktop установлен правильно:

```shell
docker --version
```

Если установка прошла успешно, команда должна вывести информацию о версии Docker.

Полезные ссылки:

* [Docker Desktop Documentation](https://docs.docker.com/desktop/)
* [Docker Get Started Guide](https://docs.docker.com/get-started/)
* [Docker Hub](https://hub.docker.com/)

### Docker Engine (Linux)

Часто путают понятия «Docker Desktop» и «Docker Engine». Docker Engine относится конкретно к подмножеству компонентов Docker Desktop, которые являются бесплатными, с открытым исходным кодом и могут быть установлены только в Linux.

Docker Engine включает в себя:

* Интерфейс командной строки Docker (CLI)
* Демон Docker (dockerd), предоставляющий интерфейс прикладного программирования (API) Docker.

Docker Engine может создавать образы контейнеров, запускать контейнеры из них и, как правило, позволяет реализовать большую часть из того, что доступно в Docker Desktop, но предназначен только для Linux и не обеспечивает всех тех возможностей для разработчиков, которые предоставляет Docker Desktop.

Полезные ссылки:

* [Docker Engine - Docker Documentation](https://docs.docker.com/engine/)

## Основы Docker

Docker – это платформа, которая упрощает процесс создания, упаковки и развертывания приложений в легковесных портативных контейнерах. В этом разделе мы рассмотрим основы Docker, его компоненты и ключевые команды, необходимые для начала работы.

### Что такое контейнер?

Контейнер – это легковесный, автономный и исполняемый пакет программного обеспечения, который включает в себя все зависимости (библиотеки, двоичные файлы и файлы конфигурации), необходимые для запуска приложения. Контейнеры изолируют приложения от их окружения, обеспечивая их единообразную работу в различных системах.

### Компоненты Docker

В экосистеме Docker существует три ключевых компонента:

* **Dockerfile**: текстовый файл, содержащий инструкции (команды) для создания Docker-образа.
* **Docker-образ**: слепок состояния контейнера, созданный из Dockerfile файла. Образы хранятся в реестре, например Docker Hub, и их можно извлечь или отправить в реестр.
* **Docker-контейнер**: работающий экземпляр Docker образа.

### Docker команды

Ниже приведены некоторые основные Docker команды, которые вы будете часто использовать:

* `docker pull <image>`: загрузить образ (`<image>`) из реестра, например Docker Hub.
* `docker build -t <image_name> <path>`: создать образ с названием (`<image_name>`) из Dockerfile файла, где `<path>` – это каталог, содержащий Dockerfile файл.
* `docker image ls`: вывести список всех образов, доступных на вашем локальном компьютере.
* `docker run -d -p <host_port>:<container_port> --name <container_name> <image>`: запустить контейнер, задав ему название (`<container_name>`), из образа (`<image>`), сопоставив порты хоста (`<host_port>`) с портами контейнера (`<container_port>`).
* `docker container ls`: вывести список всех запущенных контейнеров.
* `docker container stop <container>`: остановить работающий контейнер (`<container>`).
* `docker container rm <container>`: удалить остановленный контейнер (`<container>`).
* `docker image rm <image>`: удалить образ (`<image>`) с вашего локального компьютера.

## Сохранение данных

Docker позволяет запускать контейнеры, представляющие собой изолированные фрагменты кода, включая приложения и их зависимости, отдельно от операционной системы хоста. Контейнеры по умолчанию являются эфемерными, что означает, что любые данные, хранящиеся в контейнере, будут потеряны после завершения его работы. Чтобы решить эту проблему и сохранить данные на протяжении всего жизненного цикла контейнера, Docker предоставляет различные методы сохранения данных.

В этом разделе мы рассмотрим:

* [Docker тома (volumes)](https://github.com/MaksimDzhangirov/PHP-roadmap/edit/master/docker-roadmap.md#docker-%D1%82%D0%BE%D0%BC%D0%B0)
* [Bind Монтирование](https://github.com/MaksimDzhangirov/PHP-roadmap/edit/master/docker-roadmap.md#bind-%D0%BC%D0%BE%D0%BD%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5)
* [Docker tmpfs монтирование](https://github.com/MaksimDzhangirov/PHP-roadmap/edit/master/docker-roadmap.md#docker-tmpfs-%D0%BC%D0%BE%D0%BD%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5)

### Docker тома (volumes)

Docker тома – это предпочтительный способ сохранения данных, созданных и используемых Docker контейнером. Том – это каталог на хост-компьютере, который Docker использует для хранения файлов и каталогов, которые могут пережить жизненный цикл контейнера. Docker тома могут совместно использоваться контейнерами, и они предоставляют различные преимущества, такие как простое резервное копирование и миграция данных.

Чтобы создать том, используйте следующую команду:

```shell
docker volume create volume_name
```

Чтобы использовать том, добавьте флаг `--volume` (или `-v`) в вашу команду `docker run`:

```shell
docker run --volume volume_name:/container/path image_name
```

### Bind Монтирование

Bind монтирование позволяет сопоставить любой каталог на хост-компьютере с каталогом внутри контейнера. Этот метод может быть полезен в средах разработки, где вам необходимо изменить файлы в хост-системе, и эти изменения должны быть немедленно доступны в контейнере.

Чтобы создать bind монтирование, используйте флаг `--mount` с `type=bind` в вашу команду `docker run`:

```shell
docker run --mount type=bind,src=/host/path,dst=/container/path image_name
```

### Docker tmpfs монтирование

Docker tmpfs монтирование позволяет создать временное файловое хранилище прямо в памяти контейнера. Данные, хранящиеся в файлах tmpfs монтирования, являются быстрыми и безопасными, но будут потеряны после завершения работы контейнера.

Чтобы использовать tmpfs монтирование, добавьте флаг `--tmpfs` в вашу команду `docker run`:

```shell
docker run --tmpfs /container/path image_name
```

Используя эти методы, вы можете обеспечить сохранение данных на протяжении всего жизненного цикла контейнера, увеличивая пользу и гибкость Docker контейнеров. Не забудьте выбрать метод, который лучше всего подходит для вашего конкретного случая, будь то чаще всего рекомендуемые Docker тома, простое bind монтирование или быстрое и безопасное tmpfs монтирование.

### Эфемерная файловая система контейнера

По умолчанию хранилище внутри контейнера Docker является эфемерным, а это означает, что любые изменения или модификации данных, сделанные внутри контейнера, будут сохраняться только до тех пор, пока контейнер работает. Как только контейнер будет остановлен и удален, все связанные данные будут потеряны. Это связано с тем, что Docker контейнеры по своей природе спроектированы так, чтобы не сохранять состояние.

Это временное или кратковременное хранилище называется «эфемерной файловой системой контейнера». Это важная функция Docker, поскольку она обеспечивает быстрое и согласованное развертывание приложений в различных средах, не беспокоясь о состоянии контейнера.

#### Эфемерная файловая система и сохранение данных

Поскольку любые данные, хранящиеся в эфемерной файловой системе контейнера, теряются при остановке или удалении контейнера, это создаёт проблему для сохранения данных в приложениях. Это особенно проблематично для таких приложений, как базы данных, которым требуется сохранение данных на протяжении нескольких жизненных циклов контейнера.

Чтобы преодолеть эти проблемы, Docker предоставляет несколько методов сохранения данных, таких как:

* **Тома**: вариант хранилища, управляемый Docker, хранящийся вне файловой системы контейнера, позволяющий сохранять данные при перезапуске и удалении контейнера.
* **Bind монтирование**: отображение каталога или файла хост-машины в контейнер, позволяет эффективно совместно использовать хранилища хоста с контейнером.
* **tmpfs монтирование**: хранилище в памяти, полезно в тех случаях, когда требуется только сохранение данных в течение жизненного цикла контейнера.

Реализуя эти стратегии, Docker гарантирует, что данные приложения могут быть сохранены за пределами жизненного цикла одного контейнера, что позволяет работать с приложениями, где необходимо сохранение состояния.

### Монтирование томов

Монтирование томов – это способ сопоставить папку или файл в хост-системе с папкой или файлом внутри контейнера. Это позволяет данным сохраняться вне контейнера, даже если контейнер удален. Кроме того, несколько контейнеров могут использовать один и тот же том, что упрощает обмен данными между контейнерами.

#### Создание тома

Чтобы создать том в Docker, вам необходимо выполнить следующую команду:

```shell
docker volume create my-volume
```
Эта команда создаст том с названием `my-volume`. Вы можете просмотреть подробную информацию о созданном томе с помощью команды:

```shell
docker volume inspect my-volume
```

#### Монтирование тома в контейнер

Чтобы смонтировать том в контейнер, вам необходимо использовать флаг `-v` или `--mount` во время запуска контейнера. Например:

Используя флаг `-v`:

```shell
docker run -d -v my-volume:/data your-image
```

Используя флаг `--mount `:

```shell
docker run -d --mount source=my-volume,destination=/data your-image
```

В обоих приведенных выше примерах `my-volume` – это название тома, который мы создали ранее, а `/data` – это путь внутри контейнера, куда будет смонтирован том.

#### Совместное использование томов несколькими контейнерами

Чтобы cовместно использовать том, просто смонтируйте один и тот же том в нескольких контейнерах. Вот как можно совместно использовать `my-volume` двумя контейнерами, на которых запущены разные образы:

```shell
docker run -d -v my-volume:/data1 image1
docker run -d -v my-volume:/data2 image2
```

В этом примере `image1` и `image2` будут иметь доступ к одним и тем же данным, хранящимся в `my-volume`.

#### Удаление тома

Чтобы удалить том, вы можете использовать команду `docker volume rm`, за которой следует название тома:

```shell
docker volume rm my-volume
```

Вот и всё! Теперь у вас есть базовое представление о монтировании томов в Docker. Вы можете использовать их для эффективного и безопасного сохранения и обмена данными между вашими контейнерами.

### Bind Монтирование

Bind монтирование имеет ограниченную функциональность по сравнению с томами. При его использовании файл или каталог на хост-компьютере монтируется в контейнер. На файл или каталог ссылаются по его абсолютному пути на хост-компьютере. Напротив, когда вы используете том, в каталоге хранилища Docker на хост-компьютере создается новый каталог, и Docker управляет содержимым этого каталога.

Файл или каталог не обязательно должен уже существовать на Docker хосте. Он создается по требованию, если он еще не существует. Bind монтирование очень эффективно, но она зависит от наличия в файловой системе хост-компьютера определенной структуры каталогов.

Полезные ссылки:

* [Docker Bind Mounts](https://docs.docker.com/storage/bind-mounts/)

## Использование сторонних образов

Сторонние образы – это готовые образы контейнеров Docker, доступные в Docker Hub или других реестрах контейнеров. Эти образы создаются и поддерживаются частными лицами или организациями и могут использоваться в качестве отправной точки для ваших контейнерных приложений.

#### Поиск сторонних образов

Docker Hub – это крупнейший и самый популярный реестр образов контейнеров, содержащий как официальные образы, так и образы, поддерживаемые сообществом. Вы можете искать образы по названию или технологии, которую хотите использовать.

Например: если вы ищете образ `Node.js`, вы можете выполнить поиск по запросу «node» в Docker Hub и найти официальный образ Node.js вместе со многими другими образами, поддерживаемыми сообществом.

#### Использование образа в вашем Dockerfile

Чтобы использовать сторонний образ в своем Dockerfile, просто задайте название образа в качестве базового с помощью директивы `FROM`. Вот пример использования официального образа Node.js:

```
FROM node:14

# Остальная часть вашего Dockerfile...
```

#### Помните о проблемах, связанных с безопасностью

Имейте в виду, что сторонние образы потенциально могут иметь уязвимости, свяазнные с безопасностью или неправильные настройки. Всегда проверяйте источник образа и его репутацию, прежде чем использовать его на продакшене. Предпочитайте использовать официальные образы или образы, поддерживаемые сообществом.

#### Поддержка ваших образов

При использовании сторонних образов важно постоянно обновлять их, чтобы внедрять последние обновления безопасности и изменения зависимостей. Регулярно проверяйте наличие обновлений в базовых образах и исходя из этого пересобирайте контейнеры приложений.

### Базы данных

Запуск вашей базы данных в Docker контейнере может помочь оптимизировать процесс разработки и упростить развертывание. Docker Hub предоставляет множество готовых образов для популярных баз данных, таких как MySQL, PostgreSQL и MongoDB.

#### Пример: использование образа MySQL

Чтобы использовать базу данных MySQL, поищите официальный образ в Docker Hub:

```
docker search mysql
```

Найдите официальный образ и извлеките его:

```
docker pull mysql
```

Теперь вы можете запустить MySQL контейнер. Укажите необходимые переменные окружения, такие как `MYSQL_ROOT_PASSWORD`, и при необходимости сопоставьте порт контейнера с вашим хост-компьютером:

```
docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -p 3306:3306 -d mysql
```

Эта команда создает новый контейнер с именем `some-mysql`, устанавливает пароль для `root` пользователя равным `my-secret-pw` и сопоставляет порт 3306 на хосте с портом 3306 в контейнере.

#### Пример: использование образа PostgreSQL

Для PostgreSQL выполните действия, аналогичные описанным выше. Сначала найдите официальный образ:

```
docker search postgres
```

Извлеките образ:

```
docker pull postgres
```

Запустите PostgreSQL контейнер, указав переменные окружения, такие как `POSTGRES_PASSWORD`:

```
docker run --name some-postgres -e POSTGRES_PASSWORD=my-secret-pw -p 5432:5432 -d postgres
```

Запуск MongoDB контейнера с помощью Docker происходит по той же схеме, которая использовалась для вышеприведенных примеров. Найдите официальный образ:

```
docker search mongo
```

Извлеките образ:

```
docker pull mongo
```

Запустите MongoDB контейнер:

```
docker run --name some-mongo -p 27017:27017 -d mongo
```

### Интерактивные тестовые среды

Docker позволяет создавать изолированные одноразовые среды, которые можно удалить после завершения тестирования. Это значительно упрощает работу со сторонним программным обеспечением, тестирование различных зависимостей или версий и быстрое экспериментирование без риска повредить установленные на локальной машине версии программ.

#### Создание интерактивной тестовой среды с помощью Docker

Чтобы продемонстрировать, как настроить интерактивную тестовую среду, давайте в качестве примера воспользуемся языком программирования Python. Мы будем использовать общедоступный образ Python, который можно найти на [Docker Hub](https://hub.docker.com/_/python).

* Чтобы запустить интерактивную тестовую среду с использованием образа Python, просто выполните следующую команду:

```shell
docker run -it --rm python
```

Здесь флаг `-it` гарантирует, что вы запускаете контейнер в интерактивном режиме с tty, а флаг `--rm` удалит контейнер после его остановки.

* Теперь вы должны находиться в интерактивной оболочки Python внутри контейнера. Вы можете выполнить любую команду Python или установить дополнительные пакеты, используя `pip`, без каких-либо проблем.

```python
print("Hello, Docker!")
```

* Завершив интерактивный сеанс, вы можете просто ввести команду `exit()` или нажать `CTRL+D`, чтобы выйти из контейнера. Контейнер будет автоматически удален, как 
предусмотрено флагом `--rm`.

#### Другие примеры интерактивных тестовых сред

Вы можете использовать несколько сторонних образов, доступных в Docker Hub, и создавать различные интерактивные среды, такие как:

* **Node.js**: Чтобы запустить интерактивную оболочку Node.js, вы можете использовать следующую команду:

```
docker run -it --rm node
```

* **Ruby**: Чтобы запустить интерактивную оболочку Ruby, вы можете использовать следующую команду:

```
docker run -it --rm ruby
```

* **MySQL**: Чтобы запустить временный экземпляр MySQL, вы можете использовать следующую команду:

```
docker run -it --rm --name temp-mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=yes -p 3306:3306 mysql
```

Это запустит временный сервер MySQL, доступ к которому можно получить через порт хоста 3306. Он будет удален после остановки контейнера.

Не стесняйтесь исследовать и тестировать различное программное обеспечение, не беспокоясь о повреждении программ, находящихся на локальном компьютере, или установке ненужных зависимостей. Использование Docker для интерактивных тестовых сред позволяет более эффективно и искусно работать с различным сторонним программным обеспечением.

### Утилиты командной строки

Образы Docker могут включать утилиты командной строки или автономные приложения, которые мы можем запускать внутри контейнеров. Это может быть очень полезно при работе со сторонними образами, поскольку инструменты, которые мы хотим использовать, уже упакованы и доступны для запуска без какой-либо установки или настройки.

#### BusyBox

BusyBox – это небольшое (1–2 МБ) и простое приложение командной строки, которое предоставляет доступ к большому количеству часто используемых утилит Unix, таких как `awk`, `grep`, `vi` и т. д. Чтобы запустить BusyBox внутри Docker-контейнера, вам просто нужно извлечь образ и запустить его с помощью Docker:

```
docker pull busybox
docker run -it busybox /bin/sh
```

Попав внутрь контейнера, вы можете запустить различные утилиты BusyBox так же, как в обычной командной строке.

#### cURL

cURL – это популярный инструмент командной строки, который можно использовать для передачи данных с использованием различных сетевых протоколов. Его часто используют для тестирования API или загрузки файлов из Интернета. Чтобы воспользоваться cURL внутри Docker контейнера, вы можете использовать официальный образ cURL, доступный в Docker Hub:

```
docker pull curlimages/curl
docker run --rm curlimages/curl https://example.com
```

В этом примере флаг `--rm` используется для удаления контейнера после завершения выполнения команды. Это полезно, когда вам нужно запустить только одну команду, а затем вернуть ресурсы контейнера системе.

#### Другие утилиты командной строки

В Docker образах доступно множество утилит командной строки, включая, помимо прочего:

* `wget`: бесплатная утилита для неинтерактивной загрузки файлов из Интернета.
* `imagemagick`: мощный пакет программного обеспечения для манипулирования и преобразования изображений.
* `jq`: легкий и гибкий процессор JSON командной строки.

Чтобы использовать любой из этих инструментов, поищите их в Docker Hub и следуйте инструкциям, представленным в соответствующих репозиториях.

В заключении отметим, что использование сторонних Docker образов для утилит командной строки может сэкономить время, упростить настройку локальной среды разработки и помочь создать единообразную среду на разных машинах. Вы можете экспериментировать с различными утилитами и инструментами, расширяя свои знания и возможности использования Docker.

## Создание образов контейнеров

Образы контейнеров – это исполняемые пакеты, которые включают в себя все необходимое для запуска приложения: код, среду выполнения, системные инструменты, библиотеки и настройки. Создавая свои собственные образы, вы можете легко развертывать приложения со всеми их зависимостями на любой платформе, поддерживаемой Docker.

#### Dockerfile

Ключевым компонентом при создании образа контейнера является `Dockerfile`. По сути, это скрипт, содержащий инструкции по сборке Docker образа. Каждая инструкция в Dockerfile создает новый слой в образе, что упрощает отслеживание изменений и минимизирует размер образа. Вот простой пример Dockerfile:

```
# Используем официальный образ среды выполнения Python в качестве родительского образа
FROM python:3.7-slim

# Назначаем в качестве рабочего каталога /app
WORKDIR /app

# Скопируйте содержимое текущего каталога в контейнер в /app
COPY . /app

# Устанавливаем все необходимые пакеты, указанные в requirements.txt
RUN pip install --trusted-host pypi.python.org -r requirements.txt

# Делаем порт 80 доступным всем за пределами этого контейнера
EXPOSE 80

# Определяем переменную окружения
ENV NAME World

# Запускаем app.py после старта контейнера
CMD ["python", "app.py"]
```

#### Создание образа

После создания Dockerfile вы можете собрать образ с помощью команды `docker build`. Выполните следующую команду в терминале из каталога, содержащего Dockerfile:

```
docker build -t your-image-name .
```

Эта команда указывает Docker создать образ, используя Dockerfile в текущем каталоге (`.`), и присвоить ему название (`-t your-image-name`).

#### Изучение образов и слоёв

После успешной сборки вы можете изучить созданный образ с помощью команды `docker image`:

```
docker image ls
```

Чтобы более подробно рассмотреть отдельные слои образа, используйте команду `docker history`:

```
docker history your-image-name
```

Чтобы просмотреть слои образа, вы также можете воспользоваться командой `docker inspect`:

```
docker inspect your-image-name
```

Чтобы удалить образ, используйте команду `docker image rm`:

```
docker image rm your-image-name
```

#### Отправка образов в реестр

После создания образа вы можете отправить его в реестр контейнеров (например, Docker Hub, Google Container Registry и т. д.), чтобы легко распространять и развертывать свое приложение. Сначала войдите в реестр, используя свои учетные данные:

```
docker login
```

Затем добавьте тег к своему образу, используя URL-адрес реестра:

```
docker tag your-image-name username/repository:tag
```

Наконец, отправьте образ, отмеченный тегом, в реестр:

```
docker push username/repository:tag
```

Создание образов контейнеров – важнейший аспект использования Docker, поскольку он позволяет легко упаковывать и развертывать приложения. Создав файл Dockerfile с точными инструкциями, вы сможете легко создавать и распространять образы на различных платформах.

### Dockerfiles

Dockerfile – это текстовый документ, содержащий список инструкций, используемых движком Docker для создания образа. Каждая инструкция в Dockerfile добавляет к образу новый слой. Docker создаст образ на основе этих инструкций, после чего вы сможете запускать контейнеры из образа. Dockerfiles – это один из основных элементов *«инфраструктуры как кода»*.

#### Структура Dockerfile

Dockerfile организован в виде набора инструкций, по одной на строку. Каждая инструкция имеет определенный формат.

```
INSTRUCTION arguments
```

Ниже приведен пример простого Dockerfile:

```
# Используем официальный образ среды выполнения Python в качестве родительского образа
FROM python:3.7-slim

# Назначаем в качестве рабочего каталога /app
WORKDIR /app

# Скопируйте содержимое текущего каталога в контейнер в /app
COPY . /app

# Устанавливаем все необходимые пакеты, указанные в requirements.txt
RUN pip install --trusted-host pypi.python.org -r requirements.txt

# Делаем порт 80 доступным всем за пределами этого контейнера
EXPOSE 80

# Определяем переменную окружения
ENV NAME World

# Запускаем app.py после старта контейнера
CMD ["python", "app.py"]
```

#### Чаще всего используемые Dockerfile инструкции

Вот список некоторых чаще всего используемых инструкций Dockerfile и их назначение:

* `FROM`: задаёт базовый образ, который служит основой для сборки. Обязательно наличие `FROM` в качестве первой инструкции в Dockerfile.
* `WORKDIR`: устанавливает рабочий каталог для всех инструкций `RUN`, `CMD`, `ENTRYPOINT`, `COPY` или `ADD`. Если каталога не существует, он будет создан автоматически.
* `COPY`: копирует файлы или каталоги с хоста в файловую систему контейнера.
* `ADD`: Аналогично `COPY`, но также может работать с удаленными URL-адресами и автоматически распаковывать архивы.
* `RUN`: выполняет команду внутри образа в виде нового слоя.
* `CMD`: определяет команду по умолчанию, которая будет выполняться при запуске контейнера из образа.
* `ENTRYPOINT`: похожа на `CMD`, но он предназначена для использования контейнера в качестве исполняемого файла со своими собственными параметрами.
* `EXPOSE`: сообщает Docker, что контейнер будет прослушивать указанные сетевые порты во время выполнения.
* `ENV`: устанавливает переменные окружения для контейнера.

#### Создание образа из Dockerfile

Чтобы создать образ из Dockerfile, используйте команду `docker build`, указав контекст сборки (обычно текущий каталог) и необязательный тег для образа.

```
docker build -t my-image:tag .
```

После запуска этой команды Docker выполнит каждую инструкцию в Dockerfile по порядку, создав для каждой новый слой.

### Эффективное кэширование слоев

При создании образов контейнеров Docker кэширует вновь созданные слои. Эти слои затем можно будет использовать позже при создании других образов, что сокращает время сборки и минимизирует использование сетевого трафика. Однако, чтобы максимально эффективно использовать этот механизм кэширования, вы должны знать, как эффективно использовать кэширование слоев.

#### Как работает кэширование слоев в Docker

Docker создает новый слой для каждой инструкции (например, `RUN`, `COPY`, `ADD` и т. д.) в Dockerfile. Если инструкция не изменилась с момента последней сборки, Docker повторно использует существующий слой.

Например, рассмотрим следующий файл Dockerfile:

```
FROM node:14

WORKDIR /app

COPY package.json /app/
RUN npm install

COPY . /app/

CMD ["npm", "start"]
```

Когда вы создаете образ в первый раз, Docker выполнит каждую инструкцию и создаст для каждой из них новый слой. Если вы внесете какие-то изменения в приложение и соберете образ заново, Docker проверит, влияют ли измененные инструкции на какой-либо из слоев. Если изменения не затрагивают ни один из слоев, Docker повторно использует кэшированные слои.

#### Советы по эффективному кэшированию слоев

* **Минимизируйте изменения в Dockerfile**: постарайтесь свести к минимуму частоту изменений в Dockerfile и структурируйте свои инструкции таким образом, чтобы наиболее часто изменяемые строки были в конце файла.

* **Оптимизация контекста сборки**: используйте файл `.dockerignore`, чтобы исключить ненужные файлы из контекста сборки, которые могут привести к аннулированию кэша.

* **Используйте базовые образы меньшего размера**: маленькие базовые образы сокращают время, необходимое для его извлечения, а также количество слоев, которые необходимо кэшировать.

* **Воспользуйтесь флаг Docker `--cache-from`**: если вы используете CI/CD конвейер, вы можете указать, какой образ использовать в качестве источника кэша.

* **Объедите нескольких инструкций**. В некоторых случаях объединение инструкций (например, `RUN`) может помочь минимизировать количество слоев, делая кэширование более эффективным.

Следуя этим рекомендациям, вы сможете оптимизировать процесс кэширования слоев и сократить время сборки Docker образов, что сделает процессы разработки и развертывания более эффективными.

Полезные ссылки:

* [Docker Layer Caching](https://docs.docker.com/build/cache/)

### Размер образа и настройки безопасности

При создании образов контейнеров важно учитывать как размер образа, так и его безопасность. Размер образа влияет на скорость создания и развертывания ваших контейнеров. Меньшие образы приводят к более быстрой сборке и снижению нагрузки на сеть при загрузке образа. Безопасность имеет решающее значение, поскольку образы контейнеров могут содержать уязвимости, которые потенциально могут подвергнуть риску ваши приложения.

#### Уменьшение размера образа

* **Используйте подходящий базовый образ**: выберите меньший по размеру и более легковесный базовый образ, включающий только необходимые компоненты для вашего приложения. Например, рассмотрите возможность использования `alpine` варианта официального образа, если таковой имеется, поскольку обычно он намного меньше по размеру.

```
FROM node:14-alpine
```

* **Запускайте нескольких команд в одной инструкции `RUN`**: каждая инструкция `RUN` создает новый слой в образе, что увеличивает его размер. Объедините несколько команд в один оператор `RUN`, используя `&&`, чтобы минимизировать количество слоев и уменьшить окончательный размер образа.

```
RUN apt-get update && \
    apt-get install -y some-required-package
```

* **Удалите ненужные файлы в том же слое**: при установке пакетов или добавлении файлов в процессе сборки образа удалите временные или неиспользуемые файлы в том же слое, чтобы уменьшить окончательный размер образа.

```
RUN apt-get update && \
    apt-get install -y some-required-package && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*
```

* **Используйте многоэтапные (multi-stage) сборки:** используйте многоэтапные сборки для создания образов меньшего размера. Многоэтапные сборки позволяют использовать несколько операторов `FROM` в вашем Dockerfile. Каждый оператор `FROM` создает новый этап процесса сборки. Вы можете копировать файлы с одного этапа в другой, используя оператор `COPY --from`.

```
FROM node:14-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

FROM node:14-alpine
WORKDIR /app
COPY --from=build /app/dist ./dist
COPY package*.json ./
RUN npm install --production
CMD ["npm", "start"]
```

* **Используйте файл `.dockerignore`**: используйте файл `.dockerignore`, чтобы исключить ненужные файлы из контекста сборки, которые могут привести к аннулированию кэша и увеличению конечного размера образа.

#### Повышение безопасности

* **Постоянно обновляйте базовые образы**: регулярно обновляйте базовые образы, которые вы используете в своих файлах Dockerfile, чтобы они включали последние исправления безопасности.

* **Избегайте запуска контейнеров от имени пользователя root**: всегда используйте пользователя без полномочий `root` при запуске контейнеров, чтобы минимизировать потенциальные риски. Создайте пользователя и переключитесь на него перед запуском приложения.

```
RUN addgroup -g 1000 appuser && \
    adduser -u 1000 -G appuser -D appuser
USER appuser
```

* **Ограничьте область применения для инструкций `COPY` или `ADD`**: конкретизируйте файлы или каталоги, которые вы копируете в образ контейнера. Избегайте использования `COPY . .`, так как эта инструкция может непреднамеренно скопировать конфиденциальные файлы.

```
COPY package*.json ./
COPY src/ src/
```

* **Сканируйте образы на наличие уязвимостей**: используйте такие инструменты, как [Anchore](https://anchore.com/) или [Clair](https://github.com/quay/clair), для сканирования образов на наличие уязвимостей и исправления их перед развертыванием.

Следуя этим рекомендациям, вы сможете создавать более эффективные и безопасные образы контейнеров, что приведет к повышению производительности и снижению риска появления уязвимостей в ваших приложениях.

## Реестры контейнеров

Реестр контейнеров – это централизованная система хранения и распространения образов Docker контейнеров. Он позволяет разработчикам легко делиться и развертывать приложения в виде этих образов. Реестры контейнеров играют решающую роль в развертывании контейнерных приложений, поскольку они обеспечивают быстрый, надежный и безопасный способ распространения образов контейнеров в различных продакшен средах.

Ниже приведен список популярных реестров контейнеров, доступных сегодня:

* **Docker Hub**: Docker Hub – это реестр по умолчанию для общедоступных образов Docker, который служит платформой для совместного использования и распространения образов среди разработчиков.

* **Реестр контейнеров Google (GCR)**: GCR – это настраиваемый, безопасный и высокодоступный реестр, предоставляемый Google Cloud Platform, который идеально подходит для размещения частных образов контейнеров.

* **Amazon Elastic Container Registry (ECR)**: Amazon ECR – это реестр контейнеров Docker с большим выбором настроек, предоставляемый Amazon Web Services, предлагающий высокую масштабируемость и производительность для хранения, управления и развертывания образов контейнеров.

* **Реестр контейнеров Azure (ACR)**: ACR – это настраиваемый реестр, предоставляемый Microsoft Azure, предлагающий георепликацию, контроль доступа и интеграцию с другими службами Azure.

### DockerHub

[**DockerHub**](https://hub.docker.com/) – это облачная служба реестра, предоставляемая Docker Inc. Это общедоступный реестр контейнеров по умолчанию, в котором вы можете хранить, управлять и распространять образы Docker. DockerHub позволяет другим пользователям легко находить и использовать ваши образы или делиться своими образами с сообществом Docker.

#### Возможности DockerHub

* **Публичные и приватные репозитории**: Храните образы в общедоступных репозиториях, доступных всем, или выбирайте приватные репозитории с доступом только для вашей команды или организации.

* **Автоматические сборки**: DockerHub интегрируется с популярными репозиториями кода, такими как GitHub и Bitbucket, что позволяет вам настраивать автоматические сборки для ваших образов Docker. Всякий раз, когда вы отправляете код в репозиторий, DockerHub автоматически создает новый образ с последними изменениями.

* **Веб-хуки**: DockerHub позволяет настраивать веб-хуки для уведомления других приложений или служб о создании или обновлении образа.

* **Организации и команды**: Упростите совместную работу, создав организации и команды для управления доступом к вашим образам и репозиториям.

* **Официальные образы**: DockerHub предоставляет тщательно подобранный набор официальных образов для популярного программного обеспечения, такого как MongoDB, Node.js, Redis и т. д. Эти образы поддерживаются Docker Inc. и самим создателем программного обеспечения, обеспечивая их актуальность и безопасность.

Чтобы начать использовать DockerHub, вам необходимо создать бесплатную учетную запись на их сайте. После регистрации вы сможете создавать репозитории, управлять организациями и командами, а также просматривать доступные образы.

Когда вы будете готовы поделиться своими собственными образами, вы можете использовать инструмент командной строки Docker, чтобы отправить локальные образы в DockerHub:

```
docker login
docker tag your-image your-username/your-repository:your-tag
docker push your-username/your-repository:your-tag
```

Чтобы извлечь образы из DockerHub, вы можете воспользоваться командой `docker pull`:

```
docker pull your-username/your-repository:your-tag
```

DockerHub является отъемлемой частью процесса распространения и совместного использования Docker образов, что упрощает разработчикам развертывание приложений и управление контейнерной инфраструктурой.

### Альтернативы DockerHub (ghcr, ecr, gcr, act и т. д.)

В этом разделе мы обсудим некоторые популярные альтернативы DockerHub. Эти альтернативы предоставляют иной набор функций и возможностей, которые могут удовлетворить потребности вашего реестра контейнеров. Знание об этих альтернативах позволит вам принять более обоснованное решение при выборе реестра контейнеров для ваших Docker образов.

#### Quay.io

[**Quay.io**](https://quay.io/) от Red Hat – популярная альтернатива DockerHub, предлагающая как бесплатные, так и платные тарифные планы. Он предоставляет расширенную функционал безопасности под названием «Сканирование безопасности контейнера», которая проверяет наличие уязвимостей в образах, хранящихся в вашем репозитории. Quay.io также предоставляет такие возможности, как автоматические сборки, детальный контроль доступа пользователей и интеграцию с Git репозиторием.

#### Реестр контейнеров Google (GCR)

[**Google Container Registry (GCR)**](https://cloud.google.com/container-registry) – это служба реестра контейнеров, созданная Google Cloud Platform. Он обеспечивает масштабируемую и безопасную инфраструктуру для хранения, управления и развертывания Docker образов. GCR предлагает интеграцию с другими сервисами Google Cloud, такими как Cloud Build для автоматических сборок, сканирование уязвимостей реестра контейнеров и IAM роли для контроля доступа пользователей.

#### Amazon Elastic Container Registry (ECR)

[**Amazon Elastic Container Registry (ECR)**](https://aws.amazon.com/ecr/) – это реестр контейнеров Docker с большим выбором настроек, от Amazon Web Services (AWS), который упрощает процесс хранения, управления и развертывания Docker образов. С помощью ECR вы можете контролировать доступ к вашим образам с помощью политик AWS Identity and Access Management (IAM, управление идентификацией и доступом). ECR также интегрируется с другими сервисами AWS, такими как Lambda, Amazon ECS и ECR сканирование образов.

#### Реестр контейнеров Azure (ACR)

[**Реестр контейнеров Azure (ACR)**](https://azure.microsoft.com/en-us/services/container-registry/) – это реестр контейнеров от Microsoft Azure. Он предоставляет широкий спектр функций, включая георепликацию для обеспечения высокой доступности, ACR задачи для автоматического создания образов, сканирование контейнеров на наличие уязвимостей и интеграцию с Azure Pipelines для CI/CD. ACR также предлагает доступ к приватной сети с использованием виртуальных сетей и брандмауэров.

#### Реестр контейнеров GitHub (GHCR)

**Реестр контейнеров GitHub (GHCR)** – это сервис реестра контейнеров, предоставляемый GitHub. Он расширяет поддержку Docker в пакетах GitHub, предоставляя более оптимизированный интерфейс для управления и развертывания Docker образов. GHCR обеспечивает детальный контроль доступа, плавную интеграцию с GitHub Actions и поддержку хранения как публичных, так и приватных образов.

В заключение отметим, что существует несколько альтернатив DockerHub, каждая из которых имеет разные функции и возможности. Выбор реестра контейнеров должен основываться на ваших требованиях, таких как безопасность, масштабируемость, экономическая эффективность или интеграция с другими сервисами. Изучив эти варианты, вы сможете найти наиболее подходящий реестр контейнеров для вашего проекта.

### Рекомендации по добавлению тегов к образу

Добавление правильных тегов к Docker образам имеет решающее значение для эффективного управления контейнерами и их развертывания. В этом разделе мы обсудим некоторые рекомендации по добавлению тегов к образу.

#### Используйте семантическое управление версиями

При добавлению тегов к образу рекомендуется следовать рекомендациям по [семантическому версионированию](https://semver.org/). Семантическое управление версиями – получивший широко признанный метод, который помогает лучше поддерживать ваше приложение. Теги Docker образов должны иметь следующую структуру `<major_version>.<minor_version>.<patch>` (`<мажорная_версия>.<минорная_версия>.<патч>`). Пример: `3.2.1`.

#### Добавляйте тег 'latest' к последней версии

Docker позволяет вам добавить тег 'latest' к образу в дополнение к номеру версии. Самая последняя стабильная версия вашего образа обычно помечается как 'latest', чтобы пользователи могли быстро получить к ней доступ без необходимости указывать номер версии. Однако важно обновлять этот тег по мере выпуска новых версий.

```
docker build -t your-username/app-name:latest .
```

#### Тег должен быть информативным и единообразным

Выбирайте понятные и информативные названия тегов, которые передают назначение образа или изменения по сравнению с предыдущей версией. Ваши теги также должны быть единообразными для всех образов и репозиториев для лучшей организации и простоты использования.

#### Включите информацию о сборке и Git (необязательно)

В некоторых случаях полезно включить в тег образа информацию о сборке и Git-коммите. Это может помочь идентифицировать исходный код и окружение, которые использовались для создания образа. Пример: `app-name-1.2.3-b567-d1234efg`.

#### Используйте теги, специфичные для окружения и архитектуры

Если ваше приложение развернуто в разных окружениях (продакшен, стейдж, разработка) или имеет несколько архитектур (x86_64, amd64), вы можете использовать теги, определяющие эти различия. Пример: `your-username/app-name:1.2.3-production-amd64`.

#### При необходимости меняйте теги образов

Иногда вам может потребоваться изменить теги образа после его отправки в реестр. Например, если вы выпустили патч для своего приложения, вы можете пометить новую исправленную версию тем же тегом, что и предыдущая версия. Это позволяет более плавно обновлять приложения и сократить объем ручной работы для пользователей, которым необходимо применить патч.

#### Используйте автоматизированные инструменты сборки и добавления тегов

Рассмотрите возможность использования инструментов CI/CD (Jenkins, GitLab CI, Travis-CI) для автоматизации сборки образов и добавления тегов на основе коммитов, ветвей или других правил. Это обеспечивает единообразность и снижает вероятность ошибок, вызванных выполнением этих действий вручную.

Следуя этим рекомендациям по добавлению тегов к образу, вы создадите более организованный, удобный в сопровождении и	интуитивно понятный реестр контейнеров для ваших Docker образов.

## Запуск контейнеров

Чтобы запустить новый контейнер, мы используем команду `docker run`, за которой следует название образа. Основной синтаксис следующий:

```shell
docker run [options] IMAGE [COMMAND] [ARG...]
```

Например, для запуска официального образа Nginx мы будем использовать:

```shell
docker run -d -p 8080:80 nginx
```

Эта команда запускает новый контейнер и сопоставляет порт 8080 хоста с портом 80 контейнера.

#### Вывод списка контейнеров

Чтобы просмотреть список всех запущенных контейнеров, используйте команду `docker ps`. Чтобы просмотреть все контейнеры (включая остановленные), используйте флаг `-a`:

```
docker container ls -a
```

#### Доступ к контейнерам

Чтобы получить доступ к оболочке командной строки работающего контейнера, используйте команду `docker exec`:

```
docker exec -it CONTAINER_ID bash
```

Замените `CONTAINER_ID` на идентификатор или название нужного контейнера. Эту информацию вы можете найти в списке, который выводится по команде `docker ps`.

#### Остановка контейнеров

Чтобы остановить работающий контейнер, используйте команду `docker stop`, за которой следует идентификатор или название контейнера:

```
docker container stop CONTAINER_ID
```

#### Удаление контейнеров

Как только контейнер остановлен, мы можем удалить его с помощью команды `docker rm`, за которой следует идентификатор или название контейнера:

```
docker container rm CONTAINER_ID
```

Чтобы автоматически удалять контейнеры после завершения работы с ними, добавьте флаг `--rm` при запуске контейнера:

```
docker run --rm IMAGE
```

### docker run

В этом разделе мы обсудим команду `docker run`, которая позволяет запускать Docker контейнеры. Команда `docker run` создает новый контейнер из указанного образа и запускает его.

Основной синтаксис команды `docker run` следующий:

```
docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
```

* `OPTIONS`: это флаги командной строки, которые можно использовать для настройки параметров контейнера, таких как ограничения памяти, порты, переменные окружения и т. д.
* `IMAGE`: Docker образ, который будет запускать контейнер. Это может быть образ из Docker Hub или созданный вами образ, хранящийся локально.
* `COMMAND`: это команда, которая будет выполнена внутри контейнера при его запуске. Если не указано, будет использоваться точка входа образа (entrypoint) по умолчанию.
* `ARG...`: это необязательные аргументы, которые можно передать выполняемой команде.

#### Часто используемые флаги для настройки параметров

Вот некоторые часто используемые флаги при запуске `docker run`:

* `--name`: присвоить контейнеру название, чтобы его было легче идентифицировать и управлять им.
* `-p, --publish`: сделать доступным порт(ы) контейнера на хосте. Этот флаг полезно использовать, когда вы хотите получить доступ к сервисам, работающим внутри контейнера, извне контейнера.
* `-e, --env`: установить переменные окружения внутри контейнера. Вы можете использовать эту опцию несколько раз, чтобы установить несколько переменных.
* `-d, --detach`: запустить контейнер в отсоединённом от консоли режиме, запуская контейнер в фоновом режиме и не отображая логи в консоли.
* `-v, --volume`: примонтировать том с хоста к контейнеру. Этот флаг полезно использовать для сохранения данных, сгенерированных контейнером, или для обмена файлами между хостом и контейнером.

#### Примеры

Вот несколько примеров команд, которые помогут вам понять, как использовать `docker run`:

* Запускаем интерактивный сеанс Ubuntu контейнера:

```
docker run -it --name=my-ubuntu ubuntu
```

* Запускаем веб-сервер Nginx и делаем доступным порт 80 на хосте:

```
docker run -d --name=my-nginx -p 80:80 nginx
```

* Запускаем контейнер MySQL с задаваемыми пользователем переменными окружения для настройки базы данных:

```
docker run -d --name=my-mysql -e MYSQL_ROOT_PASSWORD=secret -e MYSQL_DATABASE=mydb -p 3306:3306 mysql
```

* Запускаем контейнер со смонтированным к нему томом:

```
docker run -d --name=my-data -v /path/on/host:/path/in/container some-image
```

### docker compose

Docker Compose – это инструмент для определения и запуска Docker приложений из нескольких контейнеров. Он позволяет создавать, управлять и запускать приложения с помощью простого файла YAML под названием `docker-compose.yml`. Этот файл описывает сервисы, сети и тома вашего приложения, что позволяет вам легко запускать контейнеры и управлять ими с помощью всего лишь одной команды.

Некоторые из преимуществ использования Docker Compose включают в себя:

* **Упрощенное управление контейнерами**: Docker Compose позволяет вам определять и настраивать все ваши сервисы, сети и тома в одном месте, что упрощает управление и сопровождение.

* **Воспроизводимые сборки**: поделитесь файлом `docker-compose.yml` с другими, чтобы убедиться, что у них то же окружение и сервисы, что и у вас.

* **Поддержка управления версиями**: файлы Docker Compose могут иметь версии для упрощения совместимости между различными версиями самого инструмента Docker Compose.

#### Создание файла Docker Compose

Чтобы создать файл `docker-compose.yml`, начните с указания версии Docker Compose, которую вы хотите использовать, а затем сервисов, которые вы хотите определить. Вот пример типичного файла `docker-compose.yml`:

```
version: "3.9"
services:
  web:
    image: nginx:latest
    ports:
      - "80:80"
  db:
    image: mysql:latest
    environment:
      MYSQL_ROOT_PASSWORD: mysecretpassword
```

В этом примере мы определили два сервиса: веб-сервер (`web`), на котором работает последняя версия образа nginx, и сервер базы данных (`db`), на котором работает MySQL. Веб-сервер предоставляет хост-компьютеру свой порт 80, а на сервере базы данных установлена переменная окружения для пароля root пользователя.

#### Запуск Docker Compose

Чтобы запустить приложение Docker Compose, просто перейдите в каталог, содержащий файл `docker-compose.yml`, и выполните следующую команду:

```
docker-compose up
```

Docker Compose считает файл и запустит заданные там сервисы в указанном порядке.

#### Другие полезные команды

* `docker-compose down`: останавливает и удаляет все запущенные контейнеры, сети и тома, определенные в файле `docker-compose.yml`.
* `docker-compose ps`: отображает состояние всех контейнеров, определенных в файле `docker-compose.yml`.
* `docker-compose logs`: отображает логи всех контейнеров, определенных в файле `docker-compose.yml`.
* `docker-compose build`: собирает все образы, определенные в файле `docker-compose.yml`.

Это краткое введение в Docker Compose! Для получения дополнительной информации ознакомьтесь с официальной [документацией Docker Compose](https://docs.docker.com/compose/).

### Настройка параметров в момент запуска

Настройка параметров в момент запуска позволяют вам настраивать поведение и ресурсы ваших Docker контейнеров при их запуске. Эти параметры могут использоваться для управления ресурсами контейнера, безопасностью и сетью. Вот краткое описание некоторых часто используемых параметров:

#### Управление ресурсами

* **ЦП**: вы можете ограничить использование ЦП контейнером с помощью опций `--cpus` и `--cpu-shares`. `--cpus` ограничивает количество ядер ЦП, которые может использовать контейнер, а `--cpu-shares` назначает относительную долю времени ЦП для контейнера.

```
docker run --cpus=2 --cpu-shares=512 your-image
```

* **Память**: вы можете ограничить и зарезервировать память для контейнера, используя параметры `--memory` и `--memory-reservation`. Это может помочь предотвратить потребление контейнером слишком большого количества системных ресурсов.

```
docker run --memory=1G --memory-reservation=500M your-image
```

#### Безопасность

* **Пользователь**: по умолчанию контейнеры запускаются от имени пользователя `root`. Чтобы повысить безопасность, вы можете использовать опцию `--user` для запуска контейнера от имени другого пользователя или UID.

```
docker run --user 1000 your-image
```

* **Корневая файловая система только для чтения**: чтобы предотвратить нежелательные изменения в файловой системе контейнера, вы можете использовать параметр `--read-only`, чтобы смонтировать корневую файловую систему как доступную только для чтения.

```
docker run --read-only your-image
```

#### Сеть

* **Открытие портов**: вы можете использовать опцию `--publish` (или `-p`), чтобы сделать доступными порты контейнера в хост-системе. Это позволяет внешним системам получать доступ к сервису внутри контейнера.

```
docker run -p 80:80 your-image
```

* **Имя хоста и DNS**. Вы можете настроить имя хоста и параметры DNS контейнера, используя опции `--hostname` и `--dns`.

```
docker run --hostname=my-container --dns=8.8.8.8 your-image
```

Добавление этих параметров в момент запуска позволит вам эффективно управлять ресурсами, безопасностью и сетевыми потребностями ваших контейнеров. Полный список доступных параметров смотри в [официальной документации](https://docs.docker.com/engine/reference/run/) Docker.

## Настройка безопасности контейнера

### Меры безопасности для защиты образа
### Меры безопасности во время выполнения

## Docker CLI

### Образы
### Контейнеры
### Тома
### Сети

## Простота и скорость разработки

### Перезагрузка налету

Несмотря на то, что мы можем ускорить создание образа с помощью кэширования слоев, мы не хотим пересобирать образ контейнера при каждом изменении кода. Вместо этого мы хотим, чтобы эти изменения немедленно отражались на поведении нашего приложения в контейнере. Мы можем добиться этого с помощью bind монтирования и утилит горячей перезагрузки!

Полезные ссылки:

* [Hot Reloading - Docker](https://courses.devopsdirective.com/docker-beginner-to-pro/lessons/11-development-workflow/01-hot-reloading)

### Отладчики

Чтобы сделать разработку с использованием контейнеров конкурентоспособной с локальной разработкой, нам нужна возможность запускать и подключаться к отладчикам внутри контейнера.

Полезные ссылки:

* [Debuggers in Docker](https://courses.devopsdirective.com/docker-beginner-to-pro/lessons/11-development-workflow/02-debug-and-test)

### Тесты

Мы хотим запускать тесты в окружении, максимально похожей на продакшен, поэтому имеет смысл делать это только внутри наших контейнеров!

Полезные ссылки:

* [Running Tests - Docker](https://courses.devopsdirective.com/docker-beginner-to-pro/lessons/11-development-workflow/03-tests)

### Непрерывная интеграция

Непрерывная интеграция – это идея автоматического выполнения некоторых действий (например, сборки, тестирования и т. д.) при отправке кода в систему контроля версий.

Что касается контейнеров, мы можем захотеть сделать следующее:

* Собрать образы контейнеров
* Выполнить тесты
* Просканировать образы контейнеров на наличие уязвимостей
* Добавить теги с полезными метаданными к образам
* Отправить в реестр контейнеров

Полезные ссылки:

* [Continuous Integration - Docker](https://courses.devopsdirective.com/docker-beginner-to-pro/lessons/11-development-workflow/04-continuous-integration-github-actions)

## Развертывание контейнеров
### PaaS альтернативы
### Kubernetes
### Docker Swarm
### Nomad

Nomad – это менеджер и планировщик кластеров, который позволяет вам развертывать, управлять и масштабировать ваши контейнерные приложения. Он автоматически обрабатывает сбои узлов, осуществляет распределение ресурсов и оркестрацию контейнеров. Nomad поддерживает запуск контейнеров Docker, а также других сред выполнения контейнеров и неконтейнерных приложений.

Чтобы больше узнать о Nomad, ознакомьтесь с [официальной документацией](https://www.nomadproject.io/docs).

--------------------------------------------------------------------------------------------------------------------------------

Продолжайте обучение, используя одну из следующих карт, связанных с этой:

[Дорожная карта Backend-разработчика](https://roadmap.sh/backend)

[Дорожная карта DevOps](https://roadmap.sh/devops)



